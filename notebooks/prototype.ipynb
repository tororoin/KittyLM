{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import KittyLM\n",
    "from KittyLM.layers import Attention, KarpathyCausalSelfAttention\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "print(KittyLM.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set seeds for reproducibility\n",
    "random.seed(42)               # Python random seed\n",
    "np.random.seed(42)            # Numpy random seed\n",
    "torch.manual_seed(42)         # PyTorch CPU seed\n",
    "# torch.cuda.manual_seed(42)    # PyTorch GPU seed (if using CUDA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class KittyLMConfig:\n",
    "    \"\"\"\n",
    "    Config according to the GPT-2 weights on huggingface.\n",
    "    Using a vocab size that is a multiple of 64 to speed up the processing\n",
    "\n",
    "    \"\"\"\n",
    "    block_size = 1024\n",
    "    vocab_size = 50304 # 50257 in the original and hf implementation weights\n",
    "    n_layer = 12\n",
    "    n_heads = 12\n",
    "    d_model = 768\n",
    "    dropout = 0.0\n",
    "    bias = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def parity_check_attn(config, input_B, input_T):\n",
    "\n",
    "    # create random input tensor\n",
    "    B, T, dim, n_heads = input_B, input_T, config.d_model, config.n_heads\n",
    "    input_tensor = torch.randn(B, T, dim)\n",
    "\n",
    "    # Calculate attention on input tensor using custom implemented attention class \n",
    "    attention_layer = Attention(config)\n",
    "    custom_output = attention_layer(input_tensor)\n",
    "    print(custom_output)\n",
    "    k_attention = KarpathyCausalSelfAttention(config)\n",
    "    k_output = k_attention(input_tensor)\n",
    "    print(k_output)\n",
    "    # Calculate attention using torch.nn.MultiheadAttention\n",
    "    # https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html\n",
    "    multihead_attn = nn.MultiheadAttention(embed_dim=dim, num_heads=n_heads, dropout=config.dropout, bias=config.bias, batch_first=True )\n",
    "    query = input_tensor.view(B, T, dim)\n",
    "    key = query.clone()\n",
    "    value = query.clone()\n",
    "\n",
    "    attn_output, attn_output_weights = multihead_attn(query, key, value)\n",
    "    print(attn_output)\n",
    "    assert k_output.size() == custom_output.size(), f\"custom attn output and pytorch attn output not same size: {custom_output.size()} vs. {attn_output.size()}\"\n",
    "    \n",
    "    diff = torch.max(torch.abs(k_output -  attn_output))\n",
    "\n",
    "    return \"diff btwn custom implemented and pytorch multihead attn\", diff.item()\n",
    "    \n",
    "print(parity_check_attn(KittyLMConfig, 1, 10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    #pass \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.d_model, 4*config.d_model, bias = config.bias)\n",
    "        self.c_proj = nn.Linear(4*config.d_model, config.d_model, bias = config.bias)\n",
    "        self.activation = nn.GELU() # avoid sudden zeroout of gradients and have a smoother actovation \n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.dropout(self.c_proj(self.activation(self.c_fc(input))))\n",
    "        \n",
    "\n",
    "class Attention(nn.Module):\n",
    "    #pass\n",
    "    def __init__(self, config):\n",
    "        super(Attention, self).__init__()\n",
    "        self.q_proj = nn.Linear(config.d_model, config.d_model, bias = config.bias)\n",
    "        self.k_proj = nn.Linear(config.d_model, config.d_model, bias = config.bias)\n",
    "        self.v_proj = nn.Linear(config.d_model, config.d_model, bias = config.bias)\n",
    "        # self.c_attn = nn.Linear(config.d_model, 3 * config.d_model, bias=config.bias)\n",
    "        # final projection after attention\n",
    "        self.projection = nn.Linear(config.d_model, config.d_model, bias = config.bias)\n",
    "\n",
    "        # these are self-explanatory\n",
    "        self.attention_dropout = nn.Dropout(config.dropout)\n",
    "        self.residual_dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "        self.n_heads = config.n_heads\n",
    "        self.d_model = config.d_model\n",
    "        self.dropout = config.dropout\n",
    "        self.head_size = self.d_model // self.n_heads\n",
    "\n",
    "        self.register_buffer(\n",
    "            'causal_mask', \n",
    "            torch.tril(torch.ones(config.block_size, config.block_size)) # create a block_size * block_size mask\n",
    "            .view(1, 1, config.block_size, config.block_size) # add singletons so that shape is B * nh * block_size * block_size\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        B, T, D = input.size() # batch, length, dimension\n",
    "\n",
    "        # reshape q,k,v to (B, nh, T, hs) from (B, T, D) -> (B, T, nh, hs) -> (B, nh, T, hs)\n",
    "        # view shouldnt be used to transpose / permute as it messes up the data. chain a \n",
    "        # seperate transpose operation to transpose the the sequence length and head dimensions \n",
    "        # q, k, v  = self.c_attn(input).split(self.d_model, dim=2)\n",
    "        q = self.q_proj(input).view(B, T, self.n_heads, self.head_size).transpose(1, 2)\n",
    "        k = self.k_proj(input).view(B, T, self.n_heads, self.head_size).transpose(1, 2)\n",
    "        v = self.v_proj(input).view(B, T, self.n_heads, self.head_size).transpose(1, 2)\n",
    "\n",
    "        # lets manually compute the attention score without einsum\n",
    "        e = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "        e = e.masked_fill(self.causal_mask[:, :, :T, :T] == 0, float('-inf'))  # masking only the actual inportant information across sequencelength and head dimension\n",
    "        alpha = F.softmax(e, dim = -1)\n",
    "        alpha = self.attention_dropout(alpha)\n",
    "        attention = alpha @ v\n",
    "        attention = attention.transpose(1, 2).contiguous().view(B, T, D) # hstack all heads\n",
    "        attention = self.projection(attention)\n",
    "        attention = self.residual_dropout(attention)\n",
    "\n",
    "        return attention\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    #pass\n",
    "    def __init__(self, d_model, bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(d_model))\n",
    "        if bias is not None:\n",
    "            self.bias = nn.Parameter(torch.ones(d_model))\n",
    "\n",
    "    def forward(self, input):\n",
    "        ln = F.layer_norm(\n",
    "            input = input,\n",
    "            normalized_shape = self.weight.shape,\n",
    "            weight = self.weight,\n",
    "            bias = self.bias\n",
    "        )\n",
    "        return ln\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#import torch\n",
    "#import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "\n",
    "#from layers import MLP, Attention, LayerNorm\n",
    "\n",
    "class KittyLMConfig:\n",
    "    \"\"\"\n",
    "    Config according to the GPT-2 weights on huggingface.\n",
    "    Using a vocab size that is a multiple of 64 to speed up the processing\n",
    "\n",
    "    \"\"\"\n",
    "    block_size = 1024\n",
    "    vocab_size = 50257 # 50257 in the original and hf implementation weights but 50304 is faster\n",
    "    n_layer = 12\n",
    "    n_heads = 12\n",
    "    d_model = 768\n",
    "    dropout = 0.0\n",
    "    bias = None\n",
    "\n",
    "class KittyLMBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.preln = LayerNorm(config.d_model, bias = config.bias)\n",
    "        self.attention = Attention(config)\n",
    "        self.postln = LayerNorm(config.d_model, bias = config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = self.preln(input)\n",
    "        input = self.attention(input)\n",
    "        input = self.postln(input)\n",
    "        output = self.mlp(input)\n",
    "        return output\n",
    "        # pass\n",
    "\n",
    "class KittyLM(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.token_embeddings = nn.Embedding(num_embeddings = config.vocab_size, embedding_dim = config.d_model)\n",
    "        self.position_embeddings = nn.Embedding(num_embeddings = config.block_size, embedding_dim = config.d_model)\n",
    "        self.blocks = nn.ModuleList([KittyLMBlock(config) for _ in range(config.n_layer)])\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.ln_f = LayerNorm(config.d_model, bias = config.bias)\n",
    "        self.lm_head = nn.Linear(config.d_model, config.vocab_size, bias = False)\n",
    "\n",
    "        # weight tying\n",
    "        self.token_embeddings.weight = self.lm_head.weight\n",
    "\n",
    "        #init weights\n",
    "        self.apply(self._init_weights)\n",
    "        for name, parameter in self.named_parameters():\n",
    "            if name.endswith('projection.weight'):\n",
    "                nn.init.normal_(parameter, mean = 0.0, std = 0.2 / math.sqrt(2 * config.n_layer))\n",
    "\n",
    "        #print(\" parameter count : %.2fM\" % (self._get_parameter_count(non_embedding = False) / 1e6))\n",
    "        print(\" parameter count : \", (self._get_parameter_count(non_embedding = False)))\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.normal_(module.weight, mean = 0.0, std = 0.2)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            nn.init.normal_(module.weight, mean = 0.0, std = 0.2)\n",
    "\n",
    "    def _get_parameter_count(self, non_embedding = True):\n",
    "\n",
    "        nparams = sum(param.numel() for param in self.parameters())\n",
    "        if non_embedding:\n",
    "            nparams -= self.position_embeddings.weight.numel()\n",
    "        return nparams\n",
    "\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        B, T = input_ids.size()\n",
    "        assert T <= self.config.block_size, \"Sequence length cannnot be greater than model capacity\"\n",
    "\n",
    "        token_embeddings = self.token_embeddings(input_ids)\n",
    "        position_ids = torch.arange(0, T, dtype=torch.long, device=input_ids.device).unsqueeze(0)\n",
    "        position_embeddings = self.position_embedding(position_ids)\n",
    "\n",
    "        x = token_embeddings + position_embeddings\n",
    "        x = self.dropout(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " parameter count :  124337664\n"
     ]
    }
   ],
   "source": [
    "k = KittyLM(KittyLMConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': KittyLM(\n",
      "  (token_embeddings): Embedding(50257, 768)\n",
      "  (position_embeddings): Embedding(1024, 768)\n",
      "  (blocks): ModuleList(\n",
      "    (0-11): 12 x KittyLMBlock(\n",
      "      (preln): LayerNorm()\n",
      "      (attention): Attention(\n",
      "        (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "        (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (postln): LayerNorm()\n",
      "      (mlp): MLP(\n",
      "        (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "        (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "        (activation): GELU(approximate='none')\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (ln_f): LayerNorm()\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      "), 'token_embeddings': Embedding(50257, 768), 'position_embeddings': Embedding(1024, 768), 'blocks': ModuleList(\n",
      "  (0-11): 12 x KittyLMBlock(\n",
      "    (preln): LayerNorm()\n",
      "    (attention): Attention(\n",
      "      (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "      (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "      (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "      (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "      (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "      (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (postln): LayerNorm()\n",
      "    (mlp): MLP(\n",
      "      (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "      (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "      (activation): GELU(approximate='none')\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "), 'blocks.0': KittyLMBlock(\n",
      "  (preln): LayerNorm()\n",
      "  (attention): Attention(\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postln): LayerNorm()\n",
      "  (mlp): MLP(\n",
      "    (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "    (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "    (activation): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "), 'blocks.0.preln': LayerNorm(), 'blocks.0.attention': Attention(\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.0.attention.q_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.0.attention.k_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.0.attention.v_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.0.attention.projection': Linear(in_features=768, out_features=768, bias=False), 'blocks.0.attention.attention_dropout': Dropout(p=0.0, inplace=False), 'blocks.0.attention.residual_dropout': Dropout(p=0.0, inplace=False), 'blocks.0.postln': LayerNorm(), 'blocks.0.mlp': MLP(\n",
      "  (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "  (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "  (activation): GELU(approximate='none')\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.0.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=False), 'blocks.0.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=False), 'blocks.0.mlp.activation': GELU(approximate='none'), 'blocks.0.mlp.dropout': Dropout(p=0.0, inplace=False), 'blocks.1': KittyLMBlock(\n",
      "  (preln): LayerNorm()\n",
      "  (attention): Attention(\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postln): LayerNorm()\n",
      "  (mlp): MLP(\n",
      "    (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "    (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "    (activation): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "), 'blocks.1.preln': LayerNorm(), 'blocks.1.attention': Attention(\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.1.attention.q_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.1.attention.k_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.1.attention.v_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.1.attention.projection': Linear(in_features=768, out_features=768, bias=False), 'blocks.1.attention.attention_dropout': Dropout(p=0.0, inplace=False), 'blocks.1.attention.residual_dropout': Dropout(p=0.0, inplace=False), 'blocks.1.postln': LayerNorm(), 'blocks.1.mlp': MLP(\n",
      "  (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "  (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "  (activation): GELU(approximate='none')\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.1.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=False), 'blocks.1.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=False), 'blocks.1.mlp.activation': GELU(approximate='none'), 'blocks.1.mlp.dropout': Dropout(p=0.0, inplace=False), 'blocks.2': KittyLMBlock(\n",
      "  (preln): LayerNorm()\n",
      "  (attention): Attention(\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postln): LayerNorm()\n",
      "  (mlp): MLP(\n",
      "    (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "    (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "    (activation): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "), 'blocks.2.preln': LayerNorm(), 'blocks.2.attention': Attention(\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.2.attention.q_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.2.attention.k_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.2.attention.v_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.2.attention.projection': Linear(in_features=768, out_features=768, bias=False), 'blocks.2.attention.attention_dropout': Dropout(p=0.0, inplace=False), 'blocks.2.attention.residual_dropout': Dropout(p=0.0, inplace=False), 'blocks.2.postln': LayerNorm(), 'blocks.2.mlp': MLP(\n",
      "  (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "  (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "  (activation): GELU(approximate='none')\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.2.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=False), 'blocks.2.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=False), 'blocks.2.mlp.activation': GELU(approximate='none'), 'blocks.2.mlp.dropout': Dropout(p=0.0, inplace=False), 'blocks.3': KittyLMBlock(\n",
      "  (preln): LayerNorm()\n",
      "  (attention): Attention(\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postln): LayerNorm()\n",
      "  (mlp): MLP(\n",
      "    (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "    (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "    (activation): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "), 'blocks.3.preln': LayerNorm(), 'blocks.3.attention': Attention(\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.3.attention.q_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.3.attention.k_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.3.attention.v_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.3.attention.projection': Linear(in_features=768, out_features=768, bias=False), 'blocks.3.attention.attention_dropout': Dropout(p=0.0, inplace=False), 'blocks.3.attention.residual_dropout': Dropout(p=0.0, inplace=False), 'blocks.3.postln': LayerNorm(), 'blocks.3.mlp': MLP(\n",
      "  (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "  (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "  (activation): GELU(approximate='none')\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.3.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=False), 'blocks.3.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=False), 'blocks.3.mlp.activation': GELU(approximate='none'), 'blocks.3.mlp.dropout': Dropout(p=0.0, inplace=False), 'blocks.4': KittyLMBlock(\n",
      "  (preln): LayerNorm()\n",
      "  (attention): Attention(\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postln): LayerNorm()\n",
      "  (mlp): MLP(\n",
      "    (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "    (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "    (activation): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "), 'blocks.4.preln': LayerNorm(), 'blocks.4.attention': Attention(\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.4.attention.q_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.4.attention.k_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.4.attention.v_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.4.attention.projection': Linear(in_features=768, out_features=768, bias=False), 'blocks.4.attention.attention_dropout': Dropout(p=0.0, inplace=False), 'blocks.4.attention.residual_dropout': Dropout(p=0.0, inplace=False), 'blocks.4.postln': LayerNorm(), 'blocks.4.mlp': MLP(\n",
      "  (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "  (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "  (activation): GELU(approximate='none')\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.4.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=False), 'blocks.4.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=False), 'blocks.4.mlp.activation': GELU(approximate='none'), 'blocks.4.mlp.dropout': Dropout(p=0.0, inplace=False), 'blocks.5': KittyLMBlock(\n",
      "  (preln): LayerNorm()\n",
      "  (attention): Attention(\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postln): LayerNorm()\n",
      "  (mlp): MLP(\n",
      "    (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "    (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "    (activation): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "), 'blocks.5.preln': LayerNorm(), 'blocks.5.attention': Attention(\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.5.attention.q_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.5.attention.k_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.5.attention.v_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.5.attention.projection': Linear(in_features=768, out_features=768, bias=False), 'blocks.5.attention.attention_dropout': Dropout(p=0.0, inplace=False), 'blocks.5.attention.residual_dropout': Dropout(p=0.0, inplace=False), 'blocks.5.postln': LayerNorm(), 'blocks.5.mlp': MLP(\n",
      "  (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "  (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "  (activation): GELU(approximate='none')\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.5.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=False), 'blocks.5.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=False), 'blocks.5.mlp.activation': GELU(approximate='none'), 'blocks.5.mlp.dropout': Dropout(p=0.0, inplace=False), 'blocks.6': KittyLMBlock(\n",
      "  (preln): LayerNorm()\n",
      "  (attention): Attention(\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postln): LayerNorm()\n",
      "  (mlp): MLP(\n",
      "    (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "    (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "    (activation): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "), 'blocks.6.preln': LayerNorm(), 'blocks.6.attention': Attention(\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.6.attention.q_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.6.attention.k_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.6.attention.v_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.6.attention.projection': Linear(in_features=768, out_features=768, bias=False), 'blocks.6.attention.attention_dropout': Dropout(p=0.0, inplace=False), 'blocks.6.attention.residual_dropout': Dropout(p=0.0, inplace=False), 'blocks.6.postln': LayerNorm(), 'blocks.6.mlp': MLP(\n",
      "  (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "  (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "  (activation): GELU(approximate='none')\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.6.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=False), 'blocks.6.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=False), 'blocks.6.mlp.activation': GELU(approximate='none'), 'blocks.6.mlp.dropout': Dropout(p=0.0, inplace=False), 'blocks.7': KittyLMBlock(\n",
      "  (preln): LayerNorm()\n",
      "  (attention): Attention(\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postln): LayerNorm()\n",
      "  (mlp): MLP(\n",
      "    (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "    (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "    (activation): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "), 'blocks.7.preln': LayerNorm(), 'blocks.7.attention': Attention(\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.7.attention.q_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.7.attention.k_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.7.attention.v_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.7.attention.projection': Linear(in_features=768, out_features=768, bias=False), 'blocks.7.attention.attention_dropout': Dropout(p=0.0, inplace=False), 'blocks.7.attention.residual_dropout': Dropout(p=0.0, inplace=False), 'blocks.7.postln': LayerNorm(), 'blocks.7.mlp': MLP(\n",
      "  (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "  (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "  (activation): GELU(approximate='none')\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.7.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=False), 'blocks.7.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=False), 'blocks.7.mlp.activation': GELU(approximate='none'), 'blocks.7.mlp.dropout': Dropout(p=0.0, inplace=False), 'blocks.8': KittyLMBlock(\n",
      "  (preln): LayerNorm()\n",
      "  (attention): Attention(\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postln): LayerNorm()\n",
      "  (mlp): MLP(\n",
      "    (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "    (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "    (activation): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "), 'blocks.8.preln': LayerNorm(), 'blocks.8.attention': Attention(\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.8.attention.q_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.8.attention.k_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.8.attention.v_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.8.attention.projection': Linear(in_features=768, out_features=768, bias=False), 'blocks.8.attention.attention_dropout': Dropout(p=0.0, inplace=False), 'blocks.8.attention.residual_dropout': Dropout(p=0.0, inplace=False), 'blocks.8.postln': LayerNorm(), 'blocks.8.mlp': MLP(\n",
      "  (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "  (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "  (activation): GELU(approximate='none')\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.8.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=False), 'blocks.8.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=False), 'blocks.8.mlp.activation': GELU(approximate='none'), 'blocks.8.mlp.dropout': Dropout(p=0.0, inplace=False), 'blocks.9': KittyLMBlock(\n",
      "  (preln): LayerNorm()\n",
      "  (attention): Attention(\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postln): LayerNorm()\n",
      "  (mlp): MLP(\n",
      "    (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "    (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "    (activation): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "), 'blocks.9.preln': LayerNorm(), 'blocks.9.attention': Attention(\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.9.attention.q_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.9.attention.k_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.9.attention.v_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.9.attention.projection': Linear(in_features=768, out_features=768, bias=False), 'blocks.9.attention.attention_dropout': Dropout(p=0.0, inplace=False), 'blocks.9.attention.residual_dropout': Dropout(p=0.0, inplace=False), 'blocks.9.postln': LayerNorm(), 'blocks.9.mlp': MLP(\n",
      "  (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "  (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "  (activation): GELU(approximate='none')\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.9.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=False), 'blocks.9.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=False), 'blocks.9.mlp.activation': GELU(approximate='none'), 'blocks.9.mlp.dropout': Dropout(p=0.0, inplace=False), 'blocks.10': KittyLMBlock(\n",
      "  (preln): LayerNorm()\n",
      "  (attention): Attention(\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postln): LayerNorm()\n",
      "  (mlp): MLP(\n",
      "    (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "    (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "    (activation): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "), 'blocks.10.preln': LayerNorm(), 'blocks.10.attention': Attention(\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.10.attention.q_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.10.attention.k_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.10.attention.v_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.10.attention.projection': Linear(in_features=768, out_features=768, bias=False), 'blocks.10.attention.attention_dropout': Dropout(p=0.0, inplace=False), 'blocks.10.attention.residual_dropout': Dropout(p=0.0, inplace=False), 'blocks.10.postln': LayerNorm(), 'blocks.10.mlp': MLP(\n",
      "  (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "  (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "  (activation): GELU(approximate='none')\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.10.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=False), 'blocks.10.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=False), 'blocks.10.mlp.activation': GELU(approximate='none'), 'blocks.10.mlp.dropout': Dropout(p=0.0, inplace=False), 'blocks.11': KittyLMBlock(\n",
      "  (preln): LayerNorm()\n",
      "  (attention): Attention(\n",
      "    (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "    (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postln): LayerNorm()\n",
      "  (mlp): MLP(\n",
      "    (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "    (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "    (activation): GELU(approximate='none')\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "), 'blocks.11.preln': LayerNorm(), 'blocks.11.attention': Attention(\n",
      "  (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (projection): Linear(in_features=768, out_features=768, bias=False)\n",
      "  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (residual_dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.11.attention.q_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.11.attention.k_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.11.attention.v_proj': Linear(in_features=768, out_features=768, bias=False), 'blocks.11.attention.projection': Linear(in_features=768, out_features=768, bias=False), 'blocks.11.attention.attention_dropout': Dropout(p=0.0, inplace=False), 'blocks.11.attention.residual_dropout': Dropout(p=0.0, inplace=False), 'blocks.11.postln': LayerNorm(), 'blocks.11.mlp': MLP(\n",
      "  (c_fc): Linear(in_features=768, out_features=3072, bias=False)\n",
      "  (c_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
      "  (activation): GELU(approximate='none')\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "), 'blocks.11.mlp.c_fc': Linear(in_features=768, out_features=3072, bias=False), 'blocks.11.mlp.c_proj': Linear(in_features=3072, out_features=768, bias=False), 'blocks.11.mlp.activation': GELU(approximate='none'), 'blocks.11.mlp.dropout': Dropout(p=0.0, inplace=False), 'dropout': Dropout(p=0.0, inplace=False), 'ln_f': LayerNorm(), 'lm_head': Linear(in_features=768, out_features=50257, bias=False)}\n"
     ]
    }
   ],
   "source": [
    "named_layers = dict(k.named_modules())\n",
    "print(named_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 6 (2775956006.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[37], line 8\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"{module} : {sum(p.numel() for p in param)}\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'if' statement on line 6\n"
     ]
    }
   ],
   "source": [
    "# for idx, (module, param) in enumerate(k.named_parameters()):\n",
    "#    print(f\"{module}.{idx} parameter count: {sum(p.numel() for p in param)}\")\n",
    "\n",
    "for module, param in k.named_parameters():\n",
    "    info = module.split(\".\")\n",
    "    if len(info) > 2:\n",
    "        \n",
    "    print(f\"{module} : {sum(p.numel() for p in param)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "d = defaultdict(lambda: defaultdict(int))\n",
    "for module, param in k.named_parameters():\n",
    "    info = module.split(\".\")\n",
    "    if len(info) > 2:\n",
    "        if len(info) == 5:\n",
    "            d[info[2]][info[3]] += param.numel()\n",
    "        elif len(info) == 4:\n",
    "            d[info[2]][\"\"] += param.numel()\n",
    "\n",
    "    else:\n",
    "        d[info[0]][\"\"] += param.numel()\n",
    "    #print(f\"{module} : {sum(p.numel() for p in param)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module: token_embeddings\n",
      "  : 38597376\n",
      "Module: position_embeddings\n",
      "  : 786432\n",
      "Module: preln\n",
      "  : 9216\n",
      "Module: attention\n",
      "  q_proj: 7077888\n",
      "  k_proj: 7077888\n",
      "  v_proj: 7077888\n",
      "  projection: 7077888\n",
      "Module: postln\n",
      "  : 9216\n",
      "Module: mlp\n",
      "  c_fc: 28311552\n",
      "  c_proj: 28311552\n",
      "Module: ln_f\n",
      "  : 768\n"
     ]
    }
   ],
   "source": [
    "for module_name, sub_dict in d.items():\n",
    "    print(f\"Module: {module_name}\")\n",
    "    \n",
    "    for param_name, count in sub_dict.items():\n",
    "        print(f\"  {param_name}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'q_proj': 7077888,\n",
       "             'k_proj': 7077888,\n",
       "             'v_proj': 7077888,\n",
       "             'projection': 7077888})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"attention\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef5ce4d60d24237a32a5679c19a7bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b061ba19e9441bade38596acb28b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/tororo.in/.cache/huggingface/hub/models--openai-community--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(repo_id='openai-community/gpt2', allow_patterns='*.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ab7eb8b02748489128e6834672a715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff0e77914304cf4bc5a780a5aae2a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd98f9935a06405d9aa8a39e8768694f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277a87894bae4986b06dfb67b27d25a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01909d68b2344e3a461adbcc76f9d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc2a0eeb035460da0bbf4d4c419b393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "hf_model = \"openai-community/gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_model)\n",
    "hf_gpt2 = AutoModelForCausalLM.from_pretrained(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(hf_gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_attn_weight = hf_gpt2.transformer.h[0].attn.c_attn.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 2304])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_attn_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 768])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_q, hf_k, hf_v = torch.split(c_attn_weight, 768, dim = -1)\n",
    "hf_q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "hidden_size = hf_gpt2.config.hidden_size\n",
    "input_ids = torch.randint(0, hf_gpt2.config.vocab_size, (2, 10))\n",
    "\n",
    "input_embed = hf_gpt2.transformer.wte(input_ids)\n",
    "input_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 2304])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# passing embd through first layer of hf gpt2 model\n",
    "\n",
    "hf_0 = hf_gpt2.transformer.h[0] # layer 0\n",
    "\n",
    "hf_qkv = hf_0.attn.c_attn(input_embed)\n",
    "hf_qkv.shape # should be batch x length x 3 * d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_hf_q, out_hf_k, out_hf_v = hf_qkv.split(768, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 768])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_hf_q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    k.blocks[0].attention.q_proj.weight = torch.nn.Parameter(hf_q)\n",
    "    k.blocks[0].attention.k_proj.weight = torch.nn.Parameter(hf_k)\n",
    "    k.blocks[0].attention.v_proj.weight = torch.nn.Parameter(hf_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_q_custom = k.blocks[0].attention.q_proj(input_embed)\n",
    "out_k_custom = k.blocks[0].attention.k_proj(input_embed)\n",
    "out_v_custom = k.blocks[0].attention.v_proj(input_embed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Query outputs do not match!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(out_hf_q, out_q_custom, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery outputs do not match!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(out_hf_k, out_k_custom, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey outputs do not match!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(out_hf_v, out_v_custom, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue outputs do not match!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Query outputs do not match!"
     ]
    }
   ],
   "source": [
    "assert torch.allclose(out_hf_q, out_q_custom, atol=1e-5), \"Query outputs do not match!\"\n",
    "assert torch.allclose(out_hf_k, out_k_custom, atol=1e-5), \"Key outputs do not match!\"\n",
    "assert torch.allclose(out_hf_v, out_v_custom, atol=1e-5), \"Value outputs do not match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4738, -0.2614, -0.0978,  ...,  0.3237, -0.0483, -0.2235],\n",
      "        [ 0.0874,  0.1473,  0.2387,  ..., -0.0770, -0.1492,  0.1507],\n",
      "        [ 0.0039,  0.0695,  0.3668,  ..., -0.1235, -0.1660, -0.0480],\n",
      "        ...,\n",
      "        [-0.2592, -0.0164,  0.1991,  ..., -0.0335,  0.1455,  0.0333],\n",
      "        [ 0.1517,  0.2170,  0.1043,  ...,  0.0827, -0.0533, -0.0071],\n",
      "        [-0.4100, -0.1924, -0.2400,  ...,  0.2170,  0.1470, -0.0557]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(k.blocks[0].attention.q_proj.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4738, -0.2614, -0.0978,  ...,  0.3237, -0.0483, -0.2235],\n",
      "        [ 0.0874,  0.1473,  0.2387,  ..., -0.0770, -0.1492,  0.1507],\n",
      "        [ 0.0039,  0.0695,  0.3668,  ..., -0.1235, -0.1660, -0.0480],\n",
      "        ...,\n",
      "        [-0.2592, -0.0164,  0.1991,  ..., -0.0335,  0.1455,  0.0333],\n",
      "        [ 0.1517,  0.2170,  0.1043,  ...,  0.0827, -0.0533, -0.0071],\n",
      "        [-0.4100, -0.1924, -0.2400,  ...,  0.2170,  0.1470, -0.0557]],\n",
      "       grad_fn=<SplitBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(hf_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.1243,  1.8245, -0.1568,  ..., -0.1497, -0.3568,  0.9658],\n",
      "         [-0.3063,  0.7632,  0.6724,  ...,  0.0888, -1.1617,  0.3162],\n",
      "         [-0.9941, -0.0599,  1.4607,  ..., -1.6881,  0.9942,  2.1041],\n",
      "         ...,\n",
      "         [ 1.1804,  0.3327, -0.2058,  ..., -0.1540, -0.1996,  0.8665],\n",
      "         [-0.8858,  0.5276,  0.6065,  ..., -0.8970,  1.4199, -0.4245],\n",
      "         [-0.8390,  0.0107, -1.0630,  ..., -0.9640, -0.7801,  0.4529]],\n",
      "\n",
      "        [[ 1.0096, -0.2976,  0.5638,  ..., -0.3491, -0.1468,  0.2377],\n",
      "         [-0.9576, -1.4123,  0.5077,  ...,  0.1489,  0.3774,  0.0109],\n",
      "         [-1.4285, -1.2211,  1.0694,  ...,  0.0785, -0.1604,  0.3087],\n",
      "         ...,\n",
      "         [ 0.0854, -0.5799,  1.0094,  ..., -0.5405, -0.3010,  0.2759],\n",
      "         [ 0.2736, -0.5153,  0.7052,  ..., -0.3818, -0.3548, -1.7167],\n",
      "         [ 0.1421, -0.2851, -0.1371,  ..., -1.1382, -0.1506, -0.9867]]],\n",
      "       grad_fn=<UnsafeViewBackward0>) torch.Size([2, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "print(out_q_custom, out_q_custom.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5046, -0.1808, -2.2492,  ...,  0.0149,  0.4377, -1.7048],\n",
      "         [-0.4218, -1.0439, -1.6336,  ...,  1.4847, -0.2523, -1.0871],\n",
      "         [-1.7190,  0.4998, -2.7904,  ...,  1.1032,  0.0187, -1.6178],\n",
      "         ...,\n",
      "         [ 0.6493, -0.1796, -0.4503,  ...,  0.8349,  0.2548, -1.8746],\n",
      "         [ 0.2289, -1.3614, -1.0591,  ...,  1.6146, -0.6533, -1.7017],\n",
      "         [ 1.1903, -0.2325, -1.1019,  ...,  0.5890, -0.5762, -1.6670]],\n",
      "\n",
      "        [[ 0.3174,  1.1568, -0.8205,  ...,  1.0714, -0.4499, -1.3563],\n",
      "         [-0.4712,  0.0095, -1.8863,  ...,  0.8182,  1.2508, -1.9979],\n",
      "         [ 0.1650, -0.3094, -0.0883,  ...,  1.3423,  0.1067, -1.1818],\n",
      "         ...,\n",
      "         [-1.1883,  0.7363, -0.6516,  ...,  1.4726, -0.3120, -1.2400],\n",
      "         [ 0.2648,  1.5586, -1.9121,  ...,  1.3525,  0.2994, -1.8890],\n",
      "         [-1.1054,  0.3067, -0.6996,  ...,  1.4577,  0.7222, -0.9795]]],\n",
      "       grad_fn=<SplitBackward0>) torch.Size([2, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "print(out_hf_q, out_hf_q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(k.blocks[0].attention.q_proj.weight.t(), hf_q), \"Query weights mismatch!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0243,  0.3447, -1.8199,  ..., -0.2612,  0.8607, -1.4671],\n",
      "         [-0.9021, -0.5185, -1.2044,  ...,  1.2086,  0.1707, -0.8494],\n",
      "         [-2.1993,  1.0252, -2.3611,  ...,  0.8270,  0.4417, -1.3800],\n",
      "         ...,\n",
      "         [ 0.1689,  0.3458, -0.0210,  ...,  0.5588,  0.6778, -1.6368],\n",
      "         [-0.2514, -0.8359, -0.6299,  ...,  1.3385, -0.2302, -1.4640],\n",
      "         [ 0.7100,  0.2929, -0.6726,  ...,  0.3129, -0.1532, -1.4293]],\n",
      "\n",
      "        [[-0.1630,  1.6822, -0.3913,  ...,  0.7953, -0.0268, -1.1185],\n",
      "         [-0.9515,  0.5349, -1.4570,  ...,  0.5421,  1.6738, -1.7602],\n",
      "         [-0.3153,  0.2160,  0.3410,  ...,  1.0662,  0.5297, -0.9441],\n",
      "         ...,\n",
      "         [-1.6686,  1.2618, -0.2224,  ...,  1.1965,  0.1110, -1.0023],\n",
      "         [-0.2155,  2.0840, -1.4828,  ...,  1.0764,  0.7224, -1.6513],\n",
      "         [-1.5857,  0.8321, -0.2703,  ...,  1.1816,  1.1453, -0.7418]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_hf_q_manual = input_embed @ hf_q\n",
    "\n",
    "print(out_hf_q_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print(torch.all(out_hf_q_manual - out_q_custom) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Q mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(out_hf_q, out_q_custom), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ mismatch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Q mismatch"
     ]
    }
   ],
   "source": [
    "assert torch.allclose(out_hf_q, out_q_custom), \"Q mismatch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5046, -0.1808, -2.2492,  ...,  0.0149,  0.4377, -1.7048],\n",
       "         [-0.4218, -1.0439, -1.6336,  ...,  1.4847, -0.2523, -1.0871],\n",
       "         [-1.7190,  0.4998, -2.7904,  ...,  1.1032,  0.0187, -1.6178],\n",
       "         ...,\n",
       "         [ 0.6493, -0.1796, -0.4503,  ...,  0.8349,  0.2548, -1.8746],\n",
       "         [ 0.2289, -1.3614, -1.0591,  ...,  1.6146, -0.6533, -1.7017],\n",
       "         [ 1.1903, -0.2325, -1.1019,  ...,  0.5890, -0.5762, -1.6670]],\n",
       "\n",
       "        [[ 0.3174,  1.1568, -0.8205,  ...,  1.0714, -0.4499, -1.3563],\n",
       "         [-0.4712,  0.0095, -1.8863,  ...,  0.8182,  1.2508, -1.9979],\n",
       "         [ 0.1650, -0.3094, -0.0883,  ...,  1.3423,  0.1067, -1.1818],\n",
       "         ...,\n",
       "         [-1.1883,  0.7363, -0.6516,  ...,  1.4726, -0.3120, -1.2400],\n",
       "         [ 0.2648,  1.5586, -1.9121,  ...,  1.3525,  0.2994, -1.8890],\n",
       "         [-1.1054,  0.3067, -0.6996,  ...,  1.4577,  0.7222, -0.9795]]],\n",
       "       grad_fn=<SplitBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_hf_q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
